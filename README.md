# EZTinker

A **minimal Tinker** clone for distributed model training - **ç”¨æˆ·åœ¨æœ¬åœ°å†™è®­ç»ƒå¾ªç¯/ç®—æ³•ï¼ŒæœåŠ¡ç«¯è´Ÿè´£æŠŠæ“ä½œå¯é åœ°è·‘åœ¨ GPU é›†ç¾¤ä¸Š**ã€‚

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

âœ¨ **å››æ ¸å¿ƒ API åŸè¯­**ï¼ˆå®Œå…¨å¯¹é½ Tinker è®¾è®¡ï¼‰:
- `forward_backward()`: å‰å‘ + åå‘ã€æ¢¯åº¦ç´¯ç§¯
- `optim_step()`: å‚æ•°æ›´æ–°
- `sample()`: æ¨ç†é‡‡æ ·
- `save_checkpoint()` / `load_checkpoint()`: ä¿å­˜/åŠ è½½ LoRA adapter + optimizer

âœ¨ **LoRA Fine-tuning è®­ç»ƒ**:
- âœ… Base model åªè¯»åŠ è½½ï¼ˆçœæ˜¾å­˜ï¼‰
- âœ… LoRA adapter é«˜æ•ˆè®­ç»ƒï¼ˆrank=1-8, alpha=2-16ï¼‰
- âœ… æ”¯æŒ Qwen2/GPT2/Phi-2 ç­‰ä¸»æµæ¨¡å‹
- âœ… æ”¯æŒå¤šç§ LoRA é…ç½®ï¼ˆrank, alpha, dropout, target_modulesï¼‰
- âœ… å®Œæ•´ checkpoint æ”¯æŒï¼ˆæ–­ç‚¹ç»­è®­ + å¤šä¸ªæ£€æŸ¥ç‚¹ï¼‰

âœ¨ **æ ‡å‡†åŒ– Loss Function æ¥å£** (Protocol-based):
- âœ… ç±»å‹å®‰å…¨ï¼šå›ºå®šå‚æ•°ç­¾å `(logits, labels, weights=None) -> Tensor`
- âœ… 5ç§å†…ç½®æŸå¤±ï¼šcross_entropy, weighted_cross_entropy, focal_loss, smooth_l1, contrastive_loss
- âœ… ç¨‹åºåŒ–æ³¨å†Œï¼š`register_loss_function(name, func)`
- âœ… æ— éœ€å­—ç¬¦ä¸²æ³¨å…¥ï¼šæ›´å®‰å…¨å¯ç»´æŠ¤
- âœ… å®Œæ•´ç±»å‹æ£€æŸ¥ï¼šIDEè‡ªåŠ¨è¡¥å…¨å’ŒéªŒè¯

âœ¨ **Job/Future å¼‚æ­¥æ¨¡å¼**:
- ä½å»¶è¿Ÿå¼‚æ­¥æäº¤è®­ç»ƒä»»åŠ¡
- è½®è¯¢è·å–ç»“æœ
- å¯é çš„æ‰§è¡Œï¼ˆå¤±è´¥è‡ªåŠ¨å›é€€ï¼‰

âœ¨ **æ•°æ®é›†æ”¯æŒ**:
- âœ… GSM8K: æ•°å­¦é—®é¢˜æ•°æ®é›†
- âœ… ShareGPT: å¯¹è¯æ ¼å¼ï¼Œæ”¯æŒå¤šç§æ–¹è¨€
- ğŸ”„ æ‰©å±•æ€§å¼ºï¼šç»Ÿä¸€çš„ Dataset æ¥å£

## ğŸ—ï¸ æ¶æ„è®¾è®¡

```
EZTinker æœåŠ¡
â”œâ”€â”€ ğŸš€ API Layer (FastAPI) - æä¾› RESTful æ¥å£
â”œâ”€â”€ ğŸ§  Training Engine (PyTorch + LoRA + Loss Functions)
â”‚   â”œâ”€â”€ TrainingRun: è®­ç»ƒçŠ¶æ€ç®¡ç†
â”‚   â”œâ”€â”€ Loss Functions: æ ‡å‡†åŒ–æŸå¤±å‡½æ•°åè®®
â”‚   â””â”€â”€ Model Manager: LoRA adapter + Base model
â”œâ”€â”€ ğŸ”® Sampling Engine (Inference) - ç‹¬ç«‹é‡‡æ ·æœåŠ¡
â”œâ”€â”€ ğŸ’¾ Checkpoint Manager - Adapter + Optimizer ä¿å­˜/æ¢å¤
â””â”€â”€ ğŸ–¥ï¸  CLI (Typer) - å‘½ä»¤è¡Œå·¥å…·

æ ¸å¿ƒæ•°æ®æµ:
Client â†HTTPâ†’ API â†Stateâ†’ TrainingRun â†LoRAâ†’ Model â†’ Training
                           â†‘                              â†“
                         Loss Function Protocol â†--[logits, labels]
```

## å®‰è£…

```bash
# ä½¿ç”¨ uv åˆ›å»ºé¡¹ç›®
uv init --lib eztinker

# å®‰è£…ä¾èµ–
uv add fastapi uvicorn typer pydantic torch transformers peft accelerate redis

# å®‰è£… Ruff
uv add --dev ruff
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¯åŠ¨ EZTinker æœåŠ¡

```bash
# å¯åŠ¨æœåŠ¡å™¨
uv run eztinker server

# å¼€å‘æ¨¡å¼ï¼ˆè‡ªåŠ¨é‡è½½ï¼‰
uv run --reload eztinker server --reload
```

æœåŠ¡å¯åŠ¨åœ¨ `http://localhost:8000`ï¼Œä½ å¯ä»¥ï¼š
- API docs: `http://localhost:8000/docs`
- Health check: `http://localhost:8000/health`

### 2. ä½¿ç”¨ Python Client API (æ¨è)

```python
from eztinker import EZTinkerClient, LossFunctionConfig

# åˆ›å»ºå®¢æˆ·ç«¯
with EZTinkerClient(base_url="http://localhost:8000") as client:
    # å¥åº·æ£€æŸ¥
    print(client.health())

    # åˆ›å»ºè®­ç»ƒ run (é»˜è®¤ä½¿ç”¨ cross_entropy loss)
    run_id = client.create_run(
        base_model="Qwen/Qwen2-0.5B-Instruct",
        lora_config={"r": 1, "lora_alpha": 2, "lora_dropout": 0.05}
    )
    print(f"Training run created: {run_id}")

    # æˆ–ä½¿ç”¨è‡ªå®šä¹‰ loss function
    run_id = client.create_run(
        base_model="gpt2",
        lora_config={"r": 8},
        loss_config=LossFunctionConfig(
            loss_type="focal_loss",
            focal_alpha=0.3,
            focal_gamma=2.5
        )
    )

    # ç”Ÿæˆæ–‡æœ¬
    text = client.sample("Hello world", max_new_tokens=50, temperature=0.8)
    print(text)

    # è·å–æ‰€æœ‰ runs
    runs = client.get_runs()
    print(runs)
```

### 3. è®­ç»ƒå¾ªç¯

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("gpt2")
text = "This is a training example"
input_ids = tokenizer(text)["input_ids"]

# Tinker é£æ ¼ï¼šç”¨æˆ·åœ¨å®¢æˆ·ç«¯å†™å¾ªç¯é€»è¾‘
for step in range(10):
    # 1. forward + backward + accumulation
    fb_response = client.forward_backward(run_id, input_ids=input_ids, target_ids=input_ids)
    job_id = fb_response["job_id"]

    # 2. optimizer step
    optim_response = client.optim_step(run_id, learning_rate=2e-4, weight_decay=0.01)
    print(f"Step: {step}, Status: {optim_response['status']}")
```

### 4. ä¿å­˜ Checkpoint

```python
# ä¿å­˜å½“å‰ adapter å’Œ optimizer
save_response = client.save_checkpoint(run_id, name="checkpoint_v1")
print(save_response)
# {"status": "completed", "adapter_path": "...", "optimizer_path": "..."}

# æ£€æŸ¥ç‚¹ä¿å­˜åœ¨: checkpoints/{run_id}/checkpoint_v1.adapter.pt
#               checkpoints/{run_id}/checkpoint_v1.optimizer.pt
```

### 5. ä½¿ç”¨è‡ªå®šä¹‰ Loss Function

```python
import torch
from eztinker.engine import register_loss_function, get_loss_function

# å®šä¹‰è‡ªå®šä¹‰æŸå¤±å‡½æ•°ï¼ˆéµå¾ª LossFunction Protocolï¼‰
def my_custom_loss(
    logits: torch.Tensor,
    labels: torch.Tensor,
    weights: torch.Tensor | None = None,
    *,
    temperature: float = 1.0,
    **kwargs,
) -> torch.Tensor:
    """Custom loss with temperature scaling."""
    shift_logits = logits[:, :-1, :].contiguous()
    shift_labels = labels[:, 1:].contiguous()

    # Apply temperature
    scaled_logits = shift_logits / temperature

    # Compute cross-entropy
    loss = torch.nn.functional.cross_entropy(
        scaled_logits.view(-1, scaled_logits.size(-1)),
        shift_labels.view(-1),
        ignore_index=kwargs.get("ignore_index", -100),
    )
    return loss

# æ³¨å†Œè‡ªå®šä¹‰æŸå¤±å‡½æ•°
register_loss_function("temperature_scaled", my_custom_loss)

# ä½¿ç”¨è‡ªå®šä¹‰æŸå¤±å‡½æ•°åˆ›å»º run
run_id = client.create_run(
    base_model="gpt2",
    loss_config=LossFunctionConfig(
        loss_type="temperature_scaled",
        # é¢å¤–çš„å‚æ•°ä¼šä¼ é€’ç»™ kwargs
        # temperature éœ€è¦åœ¨ kwargs åˆå§‹åŒ–æ—¶æŒ‡å®š
    )
)
```

## ğŸ“š API å‚è€ƒæ–‡æ¡£

è¿è¡Œ `uv run nox -s docs` è‡ªåŠ¨ç”Ÿæˆå®Œæ•´çš„ API æ–‡æ¡£åˆ° `/documents` ç›®å½•ã€‚
æ–‡æ¡£åŒ…å«æ‰€æœ‰æ¨¡å—ã€ç±»ã€æ–¹æ³•çš„è¯¦ç»†è¯´æ˜å’Œç¤ºä¾‹ã€‚

```bash
# ç”Ÿæˆæ–‡æ¡£
uv run nox -s docs

# æŸ¥çœ‹æ–‡æ¡£ï¼ˆæµè§ˆå™¨æ‰“å¼€ï¼‰
open documents/eztinker.html

# æˆ–è¿è¡Œæœ¬åœ°æœåŠ¡å™¨
cd documents && python -m http.server 8000
```

## ğŸ“¦ ç›®å½•ç»“æ„

```
eztinker/
â”œâ”€â”€ src/eztinker/
â”‚   â”œâ”€â”€ api/           # FastAPI server (RESTful endpoints)
â”‚   â”œâ”€â”€ engine/        # Training & sampling engines
â”‚   â”‚   â”œâ”€â”€ loss.py        # Standardized loss function interface
â”‚   â”‚   â”œâ”€â”€ run_manager.py # TrainingRun management
â”‚   â”‚   â””â”€â”€ sampler.py     # Inference sampling
â”‚   â”œâ”€â”€ models/        # Pydantic schemas
â”‚   â”‚   â””â”€â”€ api.py         # API models (LoRAConfig, LossFunctionConfig, etc.)
â”‚   â”œâ”€â”€ core/          # State management
â”‚   â”œâ”€â”€ dataset/       # Dataset loaders (GSM8K, ShareGPT)
â”‚   â”œâ”€â”€ rl/            # Rejection sampling utilities
â”‚   â””â”€â”€ client.py      # EZTinkerClient API
â”œâ”€â”€ checkpoints/       # Checkpoint files (gitignored)
â”œâ”€â”€ documents/         # Auto-generated API docs (gitignored)
â”œâ”€â”€ tests/             # Comprehensive test suite (32 tests)
â”œâ”€â”€ .ruff.toml         # Ruff configuration
â”œâ”€â”€ .ty.toml           # Ty type checker configuration
â”œâ”€â”€ pyproject.toml     # Project configuration
â””â”€â”€ README.md
```

## ğŸ”§ å¼€å‘å·¥å…·é“¾

ä½¿ç”¨ç°ä»£ Python æœ€å¿«é€Ÿçš„å¼€å‘å·¥å…·é“¾ï¼š

- **uv**: æé€ŸåŒ…ç®¡ç† (Rust å®ç°, 100x faster)
- **ruff**: æé€Ÿ linter å’Œ formatter (1000x faster than black+isort+flake8)
- **ty** (astral-sh/ty): æé€Ÿç±»å‹æ£€æŸ¥ (100x faster than mypy)

### å¼€å‘å·¥ä½œæµ

```bash
# 1. ä¸€é”®æ ¼å¼åŒ– + lint + ä¿®å¤
uv run nox -s fix

# 2. å®Œæ•´çš„è´¨é‡æ£€æŸ¥æµç¨‹ï¼ˆCI è‡ªåŠ¨åŒ–ï¼‰
uv run nox

# åŒ…æ‹¬ï¼š
#   - format: æ ¼å¼åŒ–ä»£ç 
#   - lint: é™æ€åˆ†æ
#   - type-check: ç±»å‹æ£€æŸ¥
#   - security: å®‰å…¨æ‰«æ (Semgrep)
#   - test: è¿è¡Œæµ‹è¯•
#   - docs: ç”Ÿæˆ API æ–‡æ¡£

# 3. å¿«é€Ÿå¼€å‘å¸¸ç”¨å‘½ä»¤
uv run nox -s fmt          # åªæ ¼å¼åŒ–
uv run nox -s lint         # åªæ£€æŸ¥ lint
uv run nox -s type-check   # åªç±»å‹æ£€æŸ¥
uv run nox -s test-fast    # è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆè·³è¿‡æ…¢æµ‹è¯•ï¼‰
```

### ç¯å¢ƒå˜é‡é…ç½®ç¤ºä¾‹

```bash
# Shell aliases (æ·»åŠ åˆ° ~/.bashrc æˆ– ~/.zshrc)
alias ezt-lint='uv run ruff check src/'
alias ezt-fmt='uv run ruff format src/'
alias ezt-type='uv run ty check'
alias ezt-qc='ezt-fmt && ezt-lint && ezt-type'
alias ezt-dev='uv run eztinker server --reload'
```

## ğŸ§ª æµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
uv run pytest tests/

# è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆè·³è¿‡ @pytest.mark.slowï¼‰
uv run pytest tests/ -m "not slow"

# è¿è¡Œç‰¹å®šæµ‹è¯•
uv run pytest tests/unit/test_api_server.py::TestCustomLossFunctions
```

æµ‹è¯•è¦†ç›–:
- âœ… 32ä¸ªå•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•
- âœ… LoRA rank=1/Qwen2/LossFunction å…¼å®¹æ€§æµ‹è¯•
- âœ… è‡ªå®šä¹‰æŸå¤±å‡½æ•°æµ‹è¯•ï¼ˆ6ä¸ªæµ‹è¯•ï¼‰
- âœ… API å­—æ®µéªŒè¯æµ‹è¯•

## ğŸ“Š EZTinker vs Tinker

| ç‰¹æ€§ | EZTinker (å½“å‰) | Tinker (å®Œæ•´ç‰ˆ) |
|------|-----------------|----------------|
| âœ… LoRA Fine-tuning | âœ… | âœ… |
| âœ… Checkpoint Management | âœ… | âœ… |
| âœ… Async/Future Pattern | âœ… | âœ… |
| âœ… Custom Loss Functions | âœ… (5å†…ç½® + æ³¨å†Œç³»ç»Ÿ) | âœ… |
| âŒ Multi-GPU Worker Pool | âŒ | âœ… |
| âŒ Clock Cycle Scheduler | âŒ | âœ… |
| âŒ OpenAI Compatible | âŒ | âœ… |

## ğŸš§ TODO (æœªæ¥å¢å¼º)

- [ ] **Batch è®­ç»ƒ**: Optimize forward_backward batch processing
- [ ] **Multi-GPU**: Distributed training support
- [ ] **OpenAI å…¼å®¹ API**: Inference API å…¼å®¹
- [ ] **Web UI**: è®­ç»ƒçŠ¶æ€å¯è§†åŒ–
- [ ] **æ›´å¤šæŸå¤±å‡½æ•°**: PPO/CISPO/DRO å¼ºåŒ–å­¦ä¹ æŸå¤±
- [ ] **Scheduler**: Clock å‘¨æœŸè°ƒåº¦ï¼ˆç±» Tinkerï¼‰

## ğŸ“„ License

MIT License - free to use, modify, distribute.