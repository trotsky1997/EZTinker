# EZTinker - Python åŒ…æ”¹è¿›

## ğŸ¯ æ”¹è¿›æ¦‚è§ˆ

### é—®é¢˜
ä¹‹å‰ EZTinker çš„ç”¨æˆ·ä½“éªŒå­˜åœ¨é—®é¢˜ï¼š
- éœ€è¦æ‰‹åŠ¨è°ƒç”¨ HTTP APIï¼ˆä¸å¤Ÿä¼˜é›…ï¼‰
- CLI åŠŸèƒ½æœ‰é™
- æ²¡æœ‰ç»Ÿä¸€çš„ Python API

### è§£å†³æ–¹æ¡ˆ
ç°åœ¨ EZTinker æä¾›äº†ä¸‰ç§ä½¿ç”¨æ–¹å¼ï¼š

## 1ï¸âƒ£ ä¼˜é›…çš„ Python Client APIï¼ˆæ¨èï¼‰

### ç®€å•çš„å¼€å§‹

```python
from eztinker import EZTinkerClient

# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆè‡ªåŠ¨æ¸…ç†èµ„æºï¼‰
with EZTinkerClient() as client:
    # åˆ›å»ºè®­ç»ƒè¿è¡Œ
    run_id = client.create_run("Qwen/Qwen2-0.5B-Instruct")

    # ç”Ÿæˆæ–‡æœ¬
    text = client.sample("Hello!", max_new_tokens=100)

    print(text)
```

### å®Œæ•´çš„è®­ç»ƒå¾ªç¯ç¤ºä¾‹

```python
from eztinker import EZTinkerClient, GSM8KDataset

# 1. åˆå§‹åŒ–
client = EZTinkerClient()

# 2. åŠ è½½æ•°æ®é›†
dataset = GSM8KDataset(split="train", max_samples=100)

# 3. åˆ›å»ºè®­ç»ƒè¿è¡Œ
run_id = client.create_run(
    base_model="Qwen/Qwen2-0.5B-Instruct",
    lora_rank=1,
    lora_alpha=2
)

# 4. è®­ç»ƒå¾ªç¯
for i in range(len(dataset)):
    question, prompt, ground_truth = dataset.get_example_question(i)

    # åˆ†è¯
    tokens = tokenizer(prompt, return_tensors="pt")
    input_ids = tokens["input_ids"].tolist()[0]

    # è®­ç»ƒæ­¥éª¤
    client.forward_backward(run_id, input_ids)
    client.optim_step(run_id, learning_rate=2e-4)

# 5. ä¿å­˜æ£€æŸ¥ç‚¹
client.save_checkpoint(run_id, "checkpoint_final")

# 6. å…³é—­å®¢æˆ·ç«¯
client.close()
```

## 2ï¸âƒ£ å¼ºå¤§çš„ CLI å·¥å…·

### CLI å‘½ä»¤æ¦‚è§ˆ

```bash
# å¯åŠ¨æœåŠ¡å™¨
eztinker server

# ç‰ˆæœ¬ä¿¡æ¯
eztinker version

# æœåŠ¡å™¨çŠ¶æ€
eztinker health
eztinker status

# è®­ç»ƒè¿è¡Œç®¡ç†
eztinker create --model MODEL         # åˆ›å»ºè¿è¡Œ
eztinker list-runs                    # åˆ—å‡ºæ‰€æœ‰è¿è¡Œ
eztinker delete RUN_ID                # åˆ é™¤è¿è¡Œ

# æ¨ç†
eztinker sample "Your prompt"         # ç”Ÿæˆæ–‡æœ¬

# æ£€æŸ¥ç‚¹ç®¡ç†
eztinker save RUN_ID NAME             # ä¿å­˜æ£€æŸ¥ç‚¹
eztinker checkpoints                  # åˆ—å‡ºæ£€æŸ¥ç‚¹
eztinker checkpoints --run-id RUN_ID  # åˆ—å‡ºæŒ‡å®šè¿è¡Œçš„æ£€æŸ¥ç‚¹

# æ¼”ç¤º
eztinker demo                         # è¿è¡Œæ‹’ç»é‡‡æ ·æ¼”ç¤º
```

### CLI ä½¿ç”¨ç¤ºä¾‹

```bash
# ç»ˆç«¯ 1: å¯åŠ¨æœåŠ¡å™¨
eztinker server \
    --host 127.0.0.1 \
    --port 8080 \
    --workers 4 \
    --checkpoints-dir data/checkpoints

# ç»ˆç«¯ 2: åˆ›å»ºè®­ç»ƒè¿è¡Œ
eztinker create \
    --model Qwen/Qwen2-0.5B-Instruct \
    --run-id custom123

# ä½¿ç”¨æ¨¡å‹
eztinker sample "ä½ å¥½ä¸–ç•Œï¼" \
    --max-tokens 200 \
    --temperature 0.8

# æŸ¥çœ‹çŠ¶æ€
eztinker status

# è¿è¡Œæ¼”ç¤º
eztinker demo
```

## 3ï¸âƒ£ åŸå§‹ HTTP APIï¼ˆä»ç„¶å¯ç”¨ï¼Œä½†ä¸æ¨èï¼‰

```python
import requests

# åˆ›å»ºè¿è¡Œ
response = requests.post(
    "http://localhost:8000/v1/runs",
    json={"base_model": "Qwen/Qwen2-0.5B-Instruct"}
)
run_id = response.json()["run_id"]

# æ¨ç†
response = requests.post(
    "http://localhost:8000/v1/sample",
    json={
        "prompt": "Hello!",
        "max_new_tokens": 100
    }
)
job_id = response.json()["job_id"]

# è½®è¯¢
result = requests.get(f"http://localhost:8000/v1/jobs/{job_id}").json()
# ...
```

## ğŸ“¦ å®‰è£…å’Œä½¿ç”¨

### æœ¬åœ°å®‰è£…

```bash
# 1. ç¡®ä¿åœ¨é¡¹ç›®ç›®å½•
cd /path/to/eztinker

# 2. å®‰è£…å¼€å‘ç‰ˆæœ¬
uv sync  # æˆ– pip install -e .

# 3. æµ‹è¯•å®‰è£…
eztinker --help
uv run python -c "from eztinker import EZTinkerClient; print('âœ“ å®‰è£…æˆåŠŸ')"
```

### Python è„šæœ¬ä½¿ç”¨

```python
# my_training.py
from eztinker import (
    EZTinkerClient,
    GSM8KDataset,
    ShareGPTDataset
)
from transformers import AutoTokenizer

# 1. å‡†å¤‡
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2-0.5B-Instruct")

# 2. é€‰æ‹©æ•°æ®é›†
## GSM8K
dataset = GSM8KDataset(split="train", max_samples=100)

## ShareGPT
sharegpt = ShareGPTDataset(
    file_path="data.json",
    tokenizer=tokenizer,
    max_samples=100
)

# 3. è®­ç»ƒ
with EZTinkerClient() as client:
    run_id = client.create_run("Qwen/Qwen2-0.5B-Instruct", lora_rank=8)
    # ... ä½ çš„è®­ç»ƒä»£ç 
```

## ğŸ”§ æ•°æ®é›†é›†æˆ

### GSM8K æ•°æ®é›†

```python
from eztinker import GSM8KDataset

dataset = GSM8KDataset(
    split="train",           # æˆ– "test"
    max_samples=100,
    use_math_verify=True     # ä½¿ç”¨ Math-Verify è¯„ä¼°
)

question, prompt, answer = dataset.get_example_question(0)
print(question)  # æ•°å­¦é—®é¢˜
print(prompt)    # æ ¼å¼åŒ–çš„æç¤º
print(answer)    # æ­£ç¡®ç­”æ¡ˆ

# è¯„ä¼°ç”Ÿæˆ
result = dataset.evaluate_answer(generated_text, answer, question)
score = result['score']  # å‡†ç¡®åº¦åˆ†æ•°
```

### ShareGPT æ•°æ®é›†

```python
from eztinker import ShareGPTDataset
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2-0.5B-Instruct")

# æ”¯æŒä¸¤ç§æ–¹è¨€æ ¼å¼ï¼š
# - Dialect A: from/value (åŸå§‹ ShareGPT)
# - Dialect B: role/content (OpenAI é£æ ¼)

dataset = ShareGPTDataset(
    file_path="data.json",  # æˆ– data.jsonl
    tokenizer=tokenizer,
    max_samples=100,
    strict=True  # ä¸¥æ ¼çš„éªŒè¯
)

# ç»Ÿè®¡æ•°æ®
print(dataset.stats)
"""
{
    'total_loaded': 100,
    'valid_conversations': 99,
    'invalid_conversations': 1,
    'total_turns': 500,
    'dialect_counts': {
        'from_value': 30,
        'role_content': 70
    }
}
"""

# è·å–å¯¹è¯
conv_id, formatted_text, num_turns = dataset.get_conversation_turns(0)
print(formatted_text)  # Qwen2 æ¨¡æ¿æ ¼å¼åŒ–
```

## ğŸš€ æ‹’ç»é‡‡æ ·è®­ç»ƒ

### æä¾›çš„æ¼”ç¤ºè„šæœ¬

æ”¯æŒ **GSM8K** å’Œ **ShareGPT**:

```bash
# ä½¿ç”¨ GSM8K æ•°æ®é›†
uv run python rejection_sft_demo.py \
    --max-samples 50 \
    --num-candidates 4 \
    --epochs 3

# ä½¿ç”¨ ShareGPT æ•°æ®é›†
uv run python rejection_sft_demo_sharegpt.py \
    --dataset-type sharegpt \
    --data-path examples/sharegpt_dialect_b.json \
    --max-samples 50 \
    --epochs 3
```

### ç›´æ¥ä»£ç ä½¿ç”¨

```python
from eztinker import (
    create_training_run,
    generate_candidates,
    select_best_candidate_and_train,
    GSM8KDataset
)

# 1. åŠ è½½æ•°æ®é›†
dataset = GSM8KDataset(split="train", max_samples=100)

# 2. åˆ›å»ºè¿è¡Œ
run_id = create_training_run(
    "Qwen/Qwen2-0.5B-Instruct",
    lora_rank=1
)

# 3. å¤„ç†ç¤ºä¾‹
for i in range(len(dataset)):
    question, prompt, ground_truth = dataset.get_example_question(i)

    # ç”Ÿæˆå€™é€‰
    candidates = generate_candidates(
        prompt=prompt,
        question=question,
        run_id=run_id,
        num_candidates=4,
        temperature=0.8
    )

    # é€‰æ‹©æœ€ä½³å¹¶è®­ç»ƒ
    result = select_best_candidate_and_train(
        run_id=run_id,
        prompt=prompt,
        candidates=candidates,
        ground_truth=ground_truth,
        question=question,
        dataset=dataset,
        learning_rate=2e-4
    )

    print(f"Candidate score: {result['selected_score']:.3f}")
```

## ğŸ“ å®Œæ•´çš„å·¥ä½œæµç¨‹ç¤ºä¾‹

### è®­ç»ƒä¸€ä¸ªæ–°æ¨¡å‹

```bash
# ç»ˆç«¯ 1: å¯åŠ¨æœåŠ¡å™¨
eztinker server --checkpoints-dir my_checkpoints &

# ç»ˆç«¯ 2: è¿è¡Œè®­ç»ƒ
python my_training.py

# ç»ˆç«¯ 3 (å¯é€‰): ç›‘æ§è¿›åº¦
eztinker status
eztinker checkpoints
```

### ä½¿ç”¨ Jupyter Notebook

```python
from eztinker import EZTinkerClient, GSM8KDataset

# åˆå§‹åŒ–
client = EZTinkerClient()
dataset = GSM8KDataset(split="train", max_samples=100)
run_id = client.create_run("Qwen/Qwen2-0.5B-Instruct", lora_rank=1)

# å°æ‰¹æ¬¡è®­ç»ƒ
for i in range(10):
    question, prompt, ground_truth = dataset.get_example_question(i)

    # ç”Ÿæˆ
    generated = client.sample(prompt, max_new_tokens=200)

    # è¯„ä¼°
    result = dataset.evaluate_answer(generated, ground_truth, question)

    print(f"Sample {i}: Score = {result['score']:.3f}")

    # è®­ç»ƒï¼ˆå¦‚æœæ»¡è¶³æ¡ä»¶ï¼‰
    # ...

# ä¿å­˜
client.save_checkpoint(run_id, "notebook_run")
```

## ğŸ“š æ›´å¤šç¤ºä¾‹

æŸ¥çœ‹ `examples/example_client_api.py` è·å–å®Œæ•´çš„äº¤äº’å¼ç¤ºä¾‹:

```bash
uv run python examples/example_client_api.py
```

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†:
1. Server health checking
2. Dataset loading (GSM8K & ShareGPT)
3. Training run creation
4. Sample generation
5. Rejection sampling workflow
6. HTTP API vs Client API comparison

## ğŸ‰ æ€»ç»“

ç°åœ¨ EZTinker æä¾›äº†å®Œæ•´ä¸ª PyPI åŒ…çš„æ–¹æ³•ï¼š

âœ… **ä¼˜é›…çš„å®¢æˆ·ç«¯ API** - è¯­æ³•ç³–å’Œä¸Šä¸‹æ–‡ç®¡ç†å™¨
âœ… **å¼ºå¤§çš„ CLI** - å®Œæ•´çš„æœåŠ¡ç®¡ç†ã€ç›‘æ§å‘½ä»¤
âœ… **å¤šç§æ•°æ®é›†æ”¯æŒ** - GSM8Kã€ShareGPT (JSON/JSONL)
âœ… **å®Œæ•´çš„å·¥ä½œæµç¨‹** - æ¼”ç¤ºè„šæœ¬ã€æµ‹è¯•æ¡ˆä¾‹
âœ… **ç»“æ„åŒ–å¯¼å‡º** - è½»æ¾çš„æ¨¡å—å¯¼å…¥
âœ… **ä¼˜ç§€æ–‡æ¡£** - ä»£ç ç¤ºä¾‹ã€ä½¿ç”¨æŒ‡å—ã€ç±»å‹æç¤º

ä¸éœ€è¦å†æ‰‹åŠ¨å¤„ç† HTTP API - åªéœ€ç”¨ `from eztinker import EZTinkerClient` å°±èƒ½å¼€å§‹ï¼