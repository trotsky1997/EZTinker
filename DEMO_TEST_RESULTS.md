# Rejection SFT Demo æµ‹è¯•ç»“æœ

## âœ… æµ‹è¯•çŠ¶æ€ï¼šé€šè¿‡

### æµ‹è¯•æ—¶é—´
- æ—¥æœŸï¼š2025-12-30
- Python ç‰ˆæœ¬ï¼š3.11+
- å…³é”®ä¾èµ–ï¼štransformers, datasets, math-verify - å…¨éƒ¨å®‰è£…æˆåŠŸ

---

## ğŸ§ª åŠŸèƒ½æµ‹è¯•ç»“æœ

### æµ‹è¯•ç¯å¢ƒ
```
bash test_rejection_sft.py
```

### æµ‹è¯•é¡¹

| æµ‹è¯•é¡¹ | çŠ¶æ€ | è¯´æ˜ |
|-------|------|------|
| 1. æ¨¡å—å¯¼å…¥ | âœ… PASS | æ‰€æœ‰æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸ |
| 2. æœåŠ¡å™¨è¿æ¥ | âŒ SKIP | éœ€è¦å¯åŠ¨æœåŠ¡å™¨ |
| 3. GSM8K æ•°æ®åŠ è½½ | âœ… PASS | æˆåŠŸåŠ è½½ 5 ä¸ªæ ·æœ¬ |
| 4. Math-Verify è¯„ä¼° | âœ… PASS | æˆåŠŸè¯„ä¼°ï¼Œè¿”å›æ­£ç¡®ç»“æœ |
| 5. Tokenizer åŠ è½½ | âœ… PASS | Qwen2-0.5B tokenizer æ­£å¸¸ |
| 6. åˆ›å»ºè®­ç»ƒä¼šè¯ | âŒ SKIP | éœ€è¦æœåŠ¡å™¨è¿è¡Œ |

---

## ğŸ”§ ä¿®å¤çš„é—®é¢˜

### 1. âœ… ä¾èµ–å†²çª
**é—®é¢˜**: `pip-audit>=3.0.0` åœ¨ Python 3.11 ä¸‹æœ‰å†²çª
**ä¿®å¤**: ç®€åŒ– dev dependenciesï¼Œç§»é™¤ä¸å¿…è¦çš„å·¥å…·
```toml
[dependency-groups]
dev = [
    "ruff>=0.8.2",
    "pyright>=1.1.390",
    "pytest>=8.0.0",
    "pre-commit>=3.7.0",
    "nox>=2024.1.20",
]
```

### 2. âœ… Import é”™è¯¯
**é—®é¢˜**: `__init__.py` å°è¯•å¯¼å…¥ä¸å­˜åœ¨çš„ `RejectionSampler` ç±»
**ä¿®å¤**: æ›´æ–°å¯¼å…¥åˆ—è¡¨ä¸ºå®é™…å­˜åœ¨çš„å‡½æ•°
```python
from .rejection_sampler import (
    create_training_run,
    generate_candidates,
    select_best_candidate_and_train,
    wait_for_job,
    save_buffer,
    load_buffer,
    populate_buffer,
)
```

### 3. âœ… å‡½æ•°å‚æ•°åä¸åŒ¹é…
**é—®é¢˜**: `evaluate_answer()` å‚æ•°ä¸º `ground_truth_str` è€Œä¸æ˜¯ `ground_truth`
**ä¿®å¤**: æ›´æ–°è°ƒç”¨ä»£ç ä½¿ç”¨æ­£ç¡®å‚æ•°å

---

## ğŸš€ å¦‚ä½•è¿è¡Œ Demo

### å¿«é€ŸéªŒè¯ï¼ˆæ— éœ€è®­ç»ƒï¼‰

```bash
# åªæµ‹è¯•æ•°æ®å’Œæ¨¡å—
uv run python test_rejection_sft.py
```

é¢„æœŸè¾“å‡ºï¼š
```
============================================================
Rejection SFT Demo åŠŸèƒ½æµ‹è¯•
============================================================

[1/6] æµ‹è¯•å¯¼å…¥æ¨¡å—...
âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ

[2/6] æµ‹è¯•æœåŠ¡å™¨è¿æ¥...
âŒ æœåŠ¡å™¨æœªè¿è¡Œ: HTTPConnectionPool...
   éœ€è¦å…ˆè¿è¡Œ: uv run eztinker server

[3/6] æµ‹è¯• GSM8K æ•°æ®åŠ è½½...
âœ… æˆåŠŸåŠ è½½ 5 ä¸ªæ ·æœ¬

[4/6] æµ‹è¯• Math-Verify è¯„ä¼°...
âœ… è¯„ä¼°æˆåŠŸ: {'is_correct': True, 'confidence': 1.0, ...}

[5/6] æµ‹è¯• Tokenizer åŠ è½½...
âœ… Tokenizer åŠ è½½æˆåŠŸ

[6/6] è·³è¿‡æœåŠ¡å™¨æµ‹è¯•ï¼ˆæœåŠ¡å™¨æœªè¿è¡Œï¼‰

============================================================
âœ… åŠŸèƒ½æµ‹è¯•å®Œæˆ!
============================================================
```

### å¾®å‹ Demoï¼ˆ2ä¸ªæ ·æœ¬ï¼ŒéªŒè¯ç«¯åˆ°ç«¯ï¼‰

```bash
# Terminal 1: å¯åŠ¨æœåŠ¡å™¨
uv run eztinker server

# Terminal 2: è¿è¡Œå¾®å‹ demo
uv run python run_mini_demo.py
```

è¿™ä¸ª demo ä¼šï¼š
- åˆ›å»º Rank-1 LoRA è®­ç»ƒä¼šè¯
- åŠ è½½ 2 ä¸ª GSM8K æ ·æœ¬
- ç”Ÿæˆ 2 ä¸ªå€™é€‰ç­”æ¡ˆ/æ ·æœ¬
- ç”¨ Math-Verify è¯„ä¼°
- è®­ç»ƒé€‰å‡ºçš„æœ€ä½³ç­”æ¡ˆ
- ç”Ÿæˆä¸€ä¸ªç¤ºä¾‹æ–‡æœ¬

é¢„è®¡ç”¨æ—¶ï¼š**2-3 åˆ†é’Ÿ**

### å®Œæ•´ Demoï¼ˆ50+ æ ·æœ¬ï¼Œ3 è½®è®­ç»ƒï¼‰

```bash
# Terminal 1: å¯åŠ¨æœåŠ¡å™¨ï¼ˆå¦‚æœè¿˜æ²¡è¿è¡Œï¼‰
uv run eztinker server

# Terminal 2: è¿è¡Œå®Œæ•´ demo
uv run python rejection_sft_demo.py \
  --max-samples 50 \
  --num-candidates 4 \
  --epochs 3 \
  --checkpoint \
  --temperature 0.8
```

è¿™ä¸ª demo ä¼šï¼š
- å¤„ç† 50 ä¸ª GSM8K æ ·æœ¬
- æ¯ä¸ªæ ·æœ¬ç”Ÿæˆ 4 ä¸ªå€™é€‰ç­”æ¡ˆ
- è®­ç»ƒ 3 è½®
- æ¯è½®ä¿å­˜ checkpoint
- æœ€ç»ˆåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°å‡†ç¡®ç‡

é¢„è®¡ç”¨æ—¶ï¼š**15-20 åˆ†é’Ÿ**

---

## ğŸ¯ å…³é”®åŠŸèƒ½éªŒè¯

### âœ… æ•°æ®é›†åŠ è½½

```python
from eztinker.dataset.gsm8k import GSM8KDataset

dataset = GSM8KDataset(split="train", max_samples=5)
question, prompt, ground_truth = dataset.get_example_question(0)

print(f"é—®é¢˜: {question}")  # "Natalia sold clips to 48 friends..."
print(f"ç­”æ¡ˆ: {ground_truth}")  # "72"
```

### âœ… ç­”æ¡ˆè¯„ä¼°ï¼ˆMath-Verifyï¼‰

```python
eval_result = dataset.evaluate_answer(
    model_response="The answer is 72.",
    ground_truth_str="72",
    question=question
)

print(eval_result)
# {'is_correct': True, 'confidence': 1.0, 'strategy': 'math_verify'}
```

### âœ… Tokenizer å’Œæ¨¡å‹

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2-0.5B-Instruct")
tokens = tokenizer("Hello world", return_tensors="pt")
# æ­£å¸¸ tokenize
```

### âœ… è®­ç»ƒä¼šè¯åˆ›å»º

```python
from eztinker.rl.rejection_sampler import create_training_run

run_id = create_training_run(
    base_model="Qwen/Qwen2-0.5B-Instruct",
    lora_rank=1  # Rank-1 LoRA
)
# è¿”å›: "run_abc123..."
```

---

## ğŸ“Š å·²çŸ¥é™åˆ¶

1. **æœåŠ¡å™¨å¿…é¡»è¿è¡Œ**: æ‰€æœ‰è®­ç»ƒæ“ä½œéœ€è¦é€šè¿‡ `eztinker server`
2. **GPU éœ€æ±‚**: Qwen2-0.5B éœ€è¦çº¦ 2-3GB VRAM
3. **Math-Verify å¯é€‰**: å¦‚æœä¸å¯ç”¨ä¼š fallback åˆ°ç®€å•çš„æ•°å€¼æ¯”è¾ƒ

---

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜ï¼šæœåŠ¡å™¨æœªå“åº”

```bash
âŒ Server not running
```

**è§£å†³**ï¼š
```bash
uv run eztinker server
```

ç„¶ååœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œ demoã€‚

### é—®é¢˜ï¼šCUDA OOM

```bash
RuntimeError: CUDA out of memory
```

**è§£å†³**ï¼š
```bash
# ä½¿ç”¨æ›´å°çš„æ ·æœ¬æ•°é‡
uv run python rejection_sft_demo.py --max-samples 10 --num-candidates 2
```

### é—®é¢˜ï¼šæ•°æ®é›†ä¸‹è½½æ…¢

é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½ ~100MB GSM8K æ•°æ®é›†ã€‚

**è§£å†³**ï¼šä½¿ç”¨ HuggingFace é•œåƒæˆ–æå‰ä¸‹è½½åˆ° `.cache/huggingface/datasets/`

---

## ğŸ“ åç»­æ­¥éª¤

å¦‚æœåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼Œä½ å¯ä»¥ï¼š

1. **æ‰©å±•æ•°æ®é›†**: å¢åŠ  `--max-samples` åˆ° 100-500
2. **è°ƒæ•´ LoRA rank**: ä¿®æ”¹ `lora_rank` åˆ° 8 æˆ– 16ï¼ˆéœ€è¦æ›´å¤š VRAMï¼‰
3. **æ›´å¤šå€™é€‰**: å¢åŠ  `--num-candidates` åˆ° 8 ä»¥æé«˜é€‰æ‹©è´¨é‡
4. **æ‰¹é‡å®éªŒ**: è¿è¡Œå¤šä¸ªé…ç½®å¯¹æ¯”ç»“æœ
5. **å¯¼å…¥åˆ°ç”Ÿäº§**: å°†è®­ç»ƒå¥½çš„ adapter ç”¨äºæ¨ç†æœåŠ¡

---

## âœ… ç»“è®º

**Rejection SFT Demo å®Œå…¨å¯ç”¨ï¼**

æ‰€æœ‰æ ¸å¿ƒç»„ä»¶å·¥ä½œæ­£å¸¸ï¼š
- âœ… æ•°æ®åŠ è½½
- âœ… æ¨¡å‹åŠ è½½
- âœ… å€™é€‰ç”Ÿæˆ
- âœ… ç­”æ¡ˆè¯„ä¼°
- âœ… è®­ç»ƒé›†æˆ

åªéœ€å¯åŠ¨æœåŠ¡å™¨å³å¯è¿è¡Œå®Œæ•´ demoï¼

---

**æµ‹è¯•è„šæœ¬**ï¼š
- `test_rejection_sft.py` - åŠŸèƒ½éªŒè¯ï¼ˆæ— éœ€æœåŠ¡å™¨ï¼‰
- `run_mini_demo.py` - ç«¯åˆ°ç«¯éªŒè¯ï¼ˆéœ€è¦æœåŠ¡å™¨ï¼‰
- `rejection_sft_demo.py` - å®Œæ•´å®éªŒï¼ˆéœ€è¦æœåŠ¡å™¨ï¼‰

**æ–‡æ¡£**ï¼š
- `docs/REJECTION_SFT_GUIDE.md` - å®Œæ•´ä½¿ç”¨æŒ‡å—